{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PfDA Assignment 1 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Introduction](#overview)  \n",
    "    - [Problem Statement](#problem-statement)\n",
    "    - [About this notebook and technologies used](#notebook)  \n",
    "    - [Goal of the project](#goal)  \n",
    "        \n",
    "\n",
    "\n",
    "2. [Investigate the types of variables involved, their likely distributions, and their relationships with each other](#investigate)\n",
    "\n",
    "    - [Types of Variables](#types-variables)\n",
    "    - [Loading Original Dataset and Python Libraries](#load-libraries)\n",
    "    - [Exploring the Original Dataset](#exploring-dataset)\n",
    "    - [Relationships between the variables](#relationships)\n",
    "    - [Observations from the original dataset](#observations-dataset)\n",
    "        \n",
    "\n",
    "\n",
    "3. [Synthesise/simulate a data set as closely matching their properties as possible.](#generate-dataset)\n",
    "\n",
    "4. [Conclusion](#conclusion)\n",
    "\n",
    "5. [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>\n",
    "\n",
    "# 1. Introduction and Project Overview: \n",
    "\n",
    "This notebook contains my submission for the Programming for Data Analysis Module 2023 module at ATU as part of the Higher Diploma in Computing and Data Analytics.\n",
    "\n",
    "<a id=\"problem-statement\"></a>\n",
    "## Problem statement:\n",
    "\n",
    "For this project you must create a data set by simulating a real-world phenomenon of your choosing. You may pick any phenomenon you wish – you might pick one that is of interest to you in your personal or professional life. Then, rather than collect data related to the phenomenon, you should model and synthesise such data using Python. We suggest you use the numpy.random package for this purpose.\n",
    "\n",
    "Specifically, in this project you should:\n",
    "- Choose a real-world phenomenon that can be measured and for which you could collect at least one-hundred data points across at least four different variables.\n",
    "- Investigate the types of variables involved, their likely distributions, and their relationships with each other.\n",
    "- Synthesise/simulate a data set as closely matching their properties as possible.\n",
    "- Detail your research and implement the simulation in a Jupyter notebook – the data set itself can simply be displayed in an output cell within the notebook.\n",
    "\n",
    "Note that this project is about simulation – you must synthesise a data set. Some students may already have some real-world data sets in their own files. It is okay to base your synthesised data set on these should you wish (please reference it if you do), but the main task in this project is to create a synthesised data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"notebook\"></a>\n",
    "## About this notebook and python libraries used\n",
    "\n",
    "This project was mainly developed using the python and the following packages:\n",
    "- Seaborn is a Python data visualization library for making attractive and informative statistical graphics in Python.\n",
    "- Pandas provides data analysis tools and is designed for working with tabular data that contains an ordered collection of columns where each column can have a different value type. \n",
    "- Numpy.random is a subpackage of the `NumPy` package for working with random numbers. NumPy is one of the most important packages for numerical and scientific computing in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"goal\"></a>\n",
    "## The goal of the project\n",
    "\n",
    "\n",
    "The end goal of this project is to simulate a real-world phenomenon across at least one hundred data points across at least 4 different variables. A dataset must be simulated or synthesised. The instructions note that it is ok to base the synthesised dataset on an actual real-world dataset but the main task is to  create a synthesised data set.\n",
    "\n",
    "### 1. Choose a real-world phenomenon that can be measured and for which you could collect at least one-hundred data points across at least four different variables\n",
    "\n",
    "I have chosen to base my synthesised dataset on the passengers on board the RMS Titanic which contains variables that are real and measurable.  The original dataset has 12 variables but for the puropses of this assignment I am only going to look at a subset of these, which are the ones that I feel may have the most correlation.\n",
    "\n",
    "The variables that I will include are;\n",
    "\n",
    "- Sex\n",
    "- Age\n",
    "- Passenger Class\n",
    "- Survived\n",
    "- Siblings/Spouse onboard\n",
    "\n",
    "### 2. Investigate the types of variables involved, their likely distributions, and their relationships with each other.\n",
    "\n",
    "First I will investigate the variables in the original dataset. I will study their distributions by looking at descriptive statistics and plots such as histograms. Using this information, I will try to create a simulated dataset that is as close to the original dataset as possible. \n",
    "\n",
    "### 3. Synthesise/simulate a data set as closely matching their properties as possible.\n",
    "\n",
    "Having studied the distributions of the real dataset by looking at statistics and plot I will use Python to simulate the data, focusing on using the `numpy.random` package as much as possible but using other Python libraries as may be required. I will look at how simulation is performed and what must be considered when simulating a dataset such as this one. I will look at how each of the variables are distributed and how they could be simulated. I will also consider the relationships between the variables.\n",
    "\n",
    "\n",
    "### 4. Detail your research and implement the simulation in a Jupyter notebook – the data set itself can simply be displayed in an output cell within the notebook.\n",
    "\n",
    "All the analysis will be documented in this notebook with the first section of code reading in the original dataset and analysing the variables and distributions.  The output of the synthesised dataset is written to a csv files which is contained in this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the types of variables involved, their likely distributions, and their relationships with each other\n",
    "\n",
    "Having identified a real-world phenomenon to simulate, the next step is to investigate the types of variables involved, their likely distributions, and their relationships with each other. To do so I need data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"types-variables\"></a>\n",
    "## Types of Variables\n",
    "\n",
    "<img src = variable_type_infographic.PNG alt = \"Data Types Infographic\">\n",
    "\n",
    "A variable is a characteristic that can be measured and that can assume different values. Height, age, income, province or country of birth, grades obtained at school and type of housing are all examples of variables. Understanding the types of variables in a dataset is crucial for performing appropriate analyses and choosing suitable machine learning algorithms for prediction tasks. Different types of variables require different statistical methods and visualization techniques for analysis.  Variables may be classified into two main categories: categorical and numeric. Each category is then classified in two subcategories: nominal or ordinal for categorical variables, discrete or continuous for numeric variables. \n",
    "\n",
    "A categorical variable (also called qualitative variable) refers to a characteristic that can’t be quantifiable. Categorical variables can be either nominal or ordinal.\n",
    "\n",
    "  - A nominal variable is one that describes a name, label or category without natural order. Sex and type of dwelling are examples of nominal variables.\n",
    "\n",
    "  - An ordinal variable is a variable whose values are defined by an order relation between the different categories.\n",
    "\n",
    "A numeric or quantative variable is a quantifiable characteristic whose values are numbers.  These variables can be either continous or discrete.\n",
    "\n",
    "  - A continous variable is one that can assume an infinite number of real values within a given interval.  Continous variables can be further categorised as either interval or ratio variables with one of the key differences being that a ration has a defined zero point.\n",
    "\n",
    "  - A discrete variable can assume only a finite number of real values within a given interval.\n",
    "\n",
    "In this dataset we have both categorical and numerical variables.\n",
    "\n",
    "  - Categorical: Survived, Sex and Embarked.  Ordinal: Pclass\n",
    "\n",
    "  - Continous: Age, Fare.  Discrete: SibSp, Parch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load-libraries\"></a>\n",
    "## Loading Original Dataset and Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules necessary for this task\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the existing dataset from the online source.\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataset information\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a summary of the numerical variables\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exploring-dataset\"></a>\n",
    "## Exploring the original dataset\n",
    "\n",
    "As mentioned above for this project I will only be looking at a subset of the original dataset.  Using the *loc* function in pandas I will create a new dataframe *df1* which only contains those variables in which I am interested and will attempt to recreate in a synthesised dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe containing only those variables from the original data that I want to use.  Using \n",
    "# the dropna() function to remove those rows that contain null values.\n",
    "df1 = df.loc[:,['Survived','Pclass','Sex','Age','SibSp']].dropna()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As I used the dropna() function above my dataframe df1 should no longer contain any null values.\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean, median, and standard diviation. \n",
    "relevant_columns = [\"Age\", \"Sex\", \"Pclass\", \"Survived\", \"SibSp\"]\n",
    "\n",
    "mean = df1[relevant_columns].mean()\n",
    "median = df1[relevant_columns].median()\n",
    "std_devs = df1[relevant_columns].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary dataframe.\n",
    "descriptive_stats = pd.DataFrame({\n",
    "    \"Mean\": mean,\n",
    "    \"Median\":median,\n",
    "    \"Standard Deviation\": std_devs\n",
    "})\n",
    "\n",
    "# Display the descriptive statistics. We can then use these when creating our synthetic dataset.\n",
    "print(descriptive_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the above descriptive statistics (mean, median, standard deviation) can be used in the code for generating the synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot for relationships.\n",
    "# https://stackoverflow.com/questions/55767312/how-to-position-suptitle\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.pairplot(df1[relevant_columns])\n",
    "plt.suptitle(\"Pairplot of Relevant Variables\", y = 1.02)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the subplots, style and palette\n",
    "sns.set(style=\"ticks\", palette=\"colorblind\")\n",
    "f,axes=plt.subplots(2,2, figsize=(9,9))\n",
    "# plot the distributions of each of the main variables.\n",
    "sns.histplot(df1['Age'].dropna(), kde=True, ax=axes[0,0], bins=10, color=\"g\");\n",
    "# set axes title\n",
    "axes[0,0].set_title(\"Age Distribution\");\n",
    "sns.histplot(df1['Pclass'].dropna(), kde=True, ax=axes[0,1], bins=10, color=\"g\");\n",
    "axes[0,1].set_title(\"Passenger Class Distribution\");\n",
    "sns.histplot(df1['SibSp'].dropna(), kde=True, ax=axes[1,0], bins=10, color=\"g\");\n",
    "axes[1,0].set_title(\"Sibling Spouse Distribution\");\n",
    "sns.histplot(df1['Sex'].dropna(), kde=True, ax=axes[1,1], bins=10, color=\"g\");\n",
    "axes[1,1].set_title(\"Sex Distribution\");\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above histplots we can visualise the distributions for each of the four variables.\n",
    "\n",
    "**Age**: This appears to follow a normal distribution with some positive skewness.\n",
    "\n",
    "**Passenger Class**: Doesn't appear to follow any obvious distribution but there are substantially more passengers in 3rd class than in either of the pother classes.\n",
    "\n",
    "**Siblings/Spouses**: The majority of passengers had no siblings or spouse onboard.  The data appears to follow a lognormal distribution.\n",
    "\n",
    "**Sex**: There were significantly more males onboard than females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the subplots, style and palette\n",
    "sns.set(style=\"ticks\", palette=\"colorblind\")\n",
    "f,axes=plt.subplots(2,2, figsize=(9,9))\n",
    "# plot the distributions of each of the main variables.\n",
    "sns.histplot(df1, x='Age', kde=True, stat=\"density\", ax=axes[0,0], bins=10, hue='Sex');\n",
    "# set axes title\n",
    "axes[0,0].set_title(\"Age Distribution by Sex\");\n",
    "sns.histplot(df1[df1['Survived']==1]['Pclass'].dropna(), kde=True, ax=axes[0,1], bins=3, color=\"g\");\n",
    "axes[0,1].set_title(\"Survivors by Passenger Class\");\n",
    "sns.histplot(df1[df1['Survived']==1]['Age'].dropna(), kde=True, ax=axes[1,0], bins=10, color=\"g\");\n",
    "axes[1,0].set_title(\"Survivors by Age\");\n",
    "sns.histplot(df1[df1['Survived']==0]['Age'].dropna(), kde=True, ax=axes[1,1], bins=10, color=\"g\");\n",
    "axes[1,1].set_title(\"Non Survivors by Age\");\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"Sex\", hue=\"Survived\",\n",
    "kind=\"count\", data=df1)\n",
    "plt.title('Survival by Sex')\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('No of passengers')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"observations-dataset\"></a>\n",
    "## Observations from original data\n",
    "\n",
    "- Overall approximately 40% of those onboard survived.\n",
    "\n",
    "- Females had a significantly higher chance of survival than males.\n",
    "\n",
    "- Younger passengers had a higher survival rate, while the elderly had lower rates.\n",
    "\n",
    "- The survival rate of first class passengers was higher than that of those passengers in second or third class.  This indicates that socio-economic status played a role in survival chances.\n",
    "\n",
    "- The distribution of age for those onboard appears to be a somewhat normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"generate-dataset\"></a>\n",
    "\n",
    "# Generate synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples in the dataset\n",
    "num_samples = 400\n",
    "\n",
    "# By adding the following criteria I can \"weight\" the distribution of males/females, survived/not survived \n",
    "# and passenger class to more accurately reflect the actual data in the original dataset.\n",
    "# https://stackoverflow.com/questions/10803135/weighted-choice-short-and-simple\n",
    "\n",
    "Sex_elements = ['male', 'female']\n",
    "weights_sex = [0.6, 0.4]\n",
    "\n",
    "Survived_elements = [0, 1]\n",
    "weights_survived = [0.6, 0.4]\n",
    "\n",
    "PassengerClass_elements = [1, 2, 3]\n",
    "weights_passengerclass = [0.25, 0.25, 0.5]\n",
    "\n",
    "# Generate synthetic features\n",
    "sex = random.choices(Sex_elements, weights_sex, k=num_samples)\n",
    "age = np.random.normal(loc=30, scale=10, size=num_samples).astype(int)\n",
    "passenger_class = random.choices(PassengerClass_elements, weights_passengerclass, k=num_samples)\n",
    "survived = random.choices(Survived_elements, weights_survived, k=num_samples)\n",
    "sibling_spouse = np.random.lognormal(mean=0.512605, sigma=0.929783, size=num_samples).astype(int)\n",
    "\n",
    "# Create a DataFrame to store the synthetic dataset\n",
    "synthetic_data = pd.DataFrame({\n",
    "    'Sex': sex,\n",
    "    'Age': age,\n",
    "    'Class': passenger_class,\n",
    "    'Survived': survived,\n",
    "    'Sibling/Spouse' : sibling_spouse})\n",
    "\n",
    "\n",
    "# Save the synthetic dataset to a CSV file\n",
    "synthetic_data.to_csv('synthetic_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataset information\n",
    "print(synthetic_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a summary of the numerical variables\n",
    "print(synthetic_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean, median, and standard diviation.  \n",
    "synthetic_relevant_columns = [\"Age\", \"Sex\", \"Class\", \"Survived\", \"Sibling/Spouse\"]\n",
    "\n",
    "mean = synthetic_data[synthetic_relevant_columns].mean()\n",
    "median = synthetic_data[synthetic_relevant_columns].median()\n",
    "std_devs = synthetic_data[synthetic_relevant_columns].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary dataframe.\n",
    "synthetic_descriptive_stats = pd.DataFrame({\n",
    "    \"Mean\": mean,\n",
    "    \"Median\":median,\n",
    "    \"Standard Deviation\": std_devs\n",
    "})\n",
    "\n",
    "# Display the descriptive statistics. We can then use these when creating our synthetic dataset.\n",
    "print(synthetic_descriptive_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the subplots, style and palette\n",
    "sns.set(style=\"ticks\", palette=\"colorblind\")\n",
    "f,axes=plt.subplots(2,2, figsize=(9,9))\n",
    "# plot the distributions of each of the main variables.\n",
    "sns.histplot(synthetic_data['Age'].dropna(), kde=True, ax=axes[0,0], bins=10, color=\"g\");\n",
    "# set axes title\n",
    "axes[0,0].set_title(\"Age Distribution\");\n",
    "sns.histplot(synthetic_data['Class'].dropna(), kde=True, ax=axes[0,1], bins=10, color=\"g\");\n",
    "axes[0,1].set_title(\"Passenger Class Distribution\");\n",
    "sns.histplot(synthetic_data['Sibling/Spouse'].dropna(), kde=True, ax=axes[1,0], bins=10, color=\"g\");\n",
    "axes[1,0].set_title(\"Sibling Spouse Distribution\");\n",
    "sns.histplot(synthetic_data['Sex'].dropna(), kde=True, ax=axes[1,1], bins=10, color=\"g\");\n",
    "axes[1,1].set_title(\"Sex Distribution\");\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the subplots, style and palette\n",
    "sns.set(style=\"ticks\", palette=\"colorblind\")\n",
    "f,axes=plt.subplots(2,2, figsize=(9,9))\n",
    "# plot the distributions of each of the main variables.\n",
    "sns.histplot(synthetic_data, x='Age', kde=True, stat=\"density\", ax=axes[0,0], bins=10, hue='Sex');\n",
    "# set axes title\n",
    "axes[0,0].set_title(\"Age Distribution by Sex\");\n",
    "sns.histplot(synthetic_data[synthetic_data['Survived']==1]['Class'].dropna(), kde=True, ax=axes[0,1], bins=10, color=\"g\");\n",
    "axes[0,1].set_title(\"Survivors by Passenger Class\");\n",
    "sns.histplot(synthetic_data[synthetic_data['Survived']==1]['Age'].dropna(), kde=True, ax=axes[1,0], bins=10, color=\"g\");\n",
    "axes[1,0].set_title(\"Survivors by Age\");\n",
    "sns.histplot(synthetic_data[synthetic_data['Survived']==0]['Age'].dropna(), kde=True, ax=axes[1,1], bins=10, color=\"g\");\n",
    "axes[1,1].set_title(\"Non Survivors by Age\");\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the subplots, style and palette\n",
    "sns.set(style=\"ticks\", palette=\"colorblind\")\n",
    "f,axes=plt.subplots(2,2, figsize=(9,9))\n",
    "# plot the distributions of each of the main variables.\n",
    "sns.histplot(synthetic_data['Age'].dropna(), kde=True, ax=axes[0,0], bins=10, color=\"g\");\n",
    "# set axes title\n",
    "axes[0,0].set_title(\"Age Distribution\");\n",
    "sns.histplot(synthetic_data['Class'].dropna(), kde=True, ax=axes[0,1], bins=10, color=\"g\");\n",
    "axes[0,1].set_title(\"Passenger Class Distribution\");\n",
    "sns.histplot(synthetic_data['Sibling/Spouse'].dropna(), kde=True, ax=axes[1,0], bins=10, color=\"g\");\n",
    "axes[1,0].set_title(\"Sibling Spouse Distribution\");\n",
    "sns.histplot(synthetic_data['Sex'].dropna(), kde=True, ax=axes[1,1], bins=10, color=\"g\");\n",
    "axes[1,1].set_title(\"Sex Distribution\");\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Comparison between Simulated and Real Data.\n",
    "# Real Data.\n",
    "print(\"Real Data: \\n\")\n",
    "print(descriptive_stats)\n",
    "print(\"---\"*21)\n",
    "\n",
    "# Synthetic data.\n",
    "print(\"Synthetic Data: \\n\")\n",
    "print(synthetic_descriptive_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "\n",
    "# 4. Conclusion\n",
    "\n",
    "The aim of the project was to create a data set by simulating a real-world phenomenon of our choosing. Then  model and synthesis relavant data using Python and the numpy.random package. In this notebook I first analysed the actual titanic dataset in order to understand the type of variables and the type of distributions they were likely to have come from and also to see how they were related to each other.\n",
    "\n",
    "Using the information derived from my actual dataset analysis I then simulated a dataset which I believe closely matches the original dataset.  As no seed was set on the final version the results will change each time the code is run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. References\n",
    "\n",
    "https://towardsdatascience.com/generating-expanding-your-datasets-with-synthetic-data-4e27716be218\n",
    "\n",
    "https://www.kdnuggets.com/2022/03/generate-tabular-synthetic-dataset.html\n",
    "\n",
    "https://data.world/nrippner/titanic-disaster-dataset\n",
    "\n",
    "https://ema.drwhy.ai/dataSetsIntro.html\n",
    "\n",
    "https://stackoverflow.com/questions/73094559/how-to-fill-a-pandas-dataframe-column-with-one-of-two-list-values\n",
    "\n",
    "https://rpubs.com/kar_ng/827540\n",
    "\n",
    "https://numpy.org/doc/stable/reference/random/legacy.html#distributions\n",
    "\n",
    "https://stackoverflow.com/questions/71948991/how-to-create-synthetic-data-based-on-dataset-with-mixed-data-types-for-classifi\n",
    "\n",
    "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
    "\n",
    "https://makeschool.org/mediabook/oa/tutorials/titanic-dataset-tutorial-an-intro-to-data-analysis-and-statistics-n40/pdfs-and-cdfs/\n",
    "\n",
    "https://dev.to/pavanbelagatti/data-analysis-of-the-titanic-with-python-koj\n",
    "\n",
    "https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html\n",
    "\n",
    "https://www.digitalocean.com/community/tutorials/pandas-dropna-drop-null-na-values-from-dataframe\n",
    "\n",
    "https://realpython.com/numpy-random-normal/#specify-the-mean-and-standard-deviation\n",
    "\n",
    "https://numpy.org/doc/stable/reference/random/generated/numpy.random.lognormal.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
